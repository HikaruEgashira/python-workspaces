# Knowledge Distillation Experiment

This project implements a knowledge distillation experiment using:
- Teacher model: claude-3-haiku (o3-mini)
- Student model: gpt-4o-mini

## Setup
```bash
poetry install
```

## Usage
```bash
poetry run python main.py
```

